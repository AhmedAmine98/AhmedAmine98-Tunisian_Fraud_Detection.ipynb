{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ahmed_Amine_Fatnassi_notebok_Tunisian_Fraud_Detection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedAmine98/AhmedAmine98-Tunisian_Fraud_Detection.ipynb/blob/master/Ahmed_Amine_Fatnassi_notebok_Tunisian_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzsZki6UTrib",
        "colab_type": "text"
      },
      "source": [
        "# **IMPORT DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2J4RgslBT1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import data from google drive :) \n",
        " \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI5IP6cXCpYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option(\"display.max_columns\", 160)  # to display all columns of our data \n",
        "\n",
        "import lightgbm as lgb                             # Modeling\n",
        "from math import sqrt\n",
        "from sklearn.metrics import make_scorer, mean_squared_error  #scoring\n",
        "from sklearn.model_selection import train_test_split  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-I2PLcwA-uE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train = pd.read_csv('/content/SUPCOM_Train.csv')\n",
        "test = pd.read_csv('/content/SUPCOM_Test.csv')\n",
        "Submission = pd.read_csv('/content/SUPCOM_SampleSubmission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "714zF5eBBuGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.shape , test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK9YzOYDWjpF",
        "colab_type": "text"
      },
      "source": [
        "# **EDA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ckkdep4WmU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at some scatter plots (only plotting for a subset of data to keep things fast)\n",
        "sample = train.sample(10000)\n",
        "plt.scatter(sample['TVA_TOTDUE'], sample['target'], alpha=0.3 , )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBK59kVIWmSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(sample['CTR_MATFIS'], sample['target'], alpha=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVaH0MIdn74t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot trend year-on-year\n",
        "train.groupby('EXE_EXERCI').mean().reset_index().plot(y='target', x='EXE_EXERCI', kind='bar')\n",
        "                                                #ylim=(0, 0.03))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD5W_aWsn7-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot trend year-on-year\n",
        "train.groupby('RES_ANNIMP').mean().reset_index().plot(y='target', x='RES_ANNIMP', kind='bar')\n",
        "                                                #ylim=(0, 0.03))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKL2f8snn77W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's plot precipitation and burn area on the same plot - note the inverse relationship, and the strong periodic component to both.\n",
        "ax = train.groupby('RES_ANNIMP').mean().reset_index().plot(y='target', x='RES_ANNIMP')\n",
        "train.groupby('RES_ANNIMP').mean().reset_index().plot(y='TVA_TOTDUE', x='RES_ANNIMP', ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n_ekaDPUR-x",
        "colab_type": "text"
      },
      "source": [
        "# **Feature  Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDvK9zGxKmvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Label encoder : \n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "train['CTR_CATEGO_X'] = LabelEncoder().fit_transform(train['CTR_CATEGO_X'])\n",
        "test['CTR_CATEGO_X'] = LabelEncoder().fit_transform(test['CTR_CATEGO_X'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUl_gxJoJJzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols_with_missing = [col for col in train \n",
        "                     if (train[col].isnull().sum()>17800)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi127dDIKJ8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.drop(cols_with_missing, axis=1, inplace=True)\n",
        "test.drop(cols_with_missing, axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtkNg6fNYVKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = train.target  # TARGET \n",
        "testID = test.id       # GET  ID to create our submission correctly \n",
        "\n",
        "train.drop(['id','target'],1,inplace=True)\n",
        "test.drop(['id',],1,inplace=True)           # delete id from test || target & id from train because we haven't target in test :) ->Same shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU4ZUFfpStC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ERzFvIUqLp",
        "colab_type": "text"
      },
      "source": [
        "**<h3> Fillna : fill Nans with Mean : Not the best Approach but try to get a methodic fillna :) </h3>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR8U6CRuU5-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "To_convert_to_int = ['CTR_OFODEP','CTR_OFODET','CTR_OBLAUT','CTR_OBLASS','CTR_ODTIMB','CTR_OBLTCL','CTR_OBLTHO','CTR_OBLDLI','CTR_OBLTVI',]\n",
        "train[To_convert_to_int] = train[To_convert_to_int].fillna(-1)\n",
        "train[To_convert_to_int] = train[To_convert_to_int].astype('int16')\n",
        "\n",
        "test[To_convert_to_int] = test[To_convert_to_int].fillna(-1)\n",
        "test[To_convert_to_int] = test[To_convert_to_int].astype('int16')\n",
        "\n",
        "train.fillna(train.mean(),inplace=True) # when you work with models like RandomForest assert that you haven't nans in your data \n",
        "test.fillna(test.mean(),inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zkdqrXzkica",
        "colab_type": "text"
      },
      "source": [
        "# **Modeling : Cross-Validation-LGBM + Prediction**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfzChej1kqOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params ={'colsample_bytree':0.85,'learning_rate':0.03,'max_depth':8,'n_estimators':3000,'num_leaves':150,\n",
        "                               'silent':False,'metric':'rmse','objective':'regression'}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys_LcO8AkzKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_iters = 7\n",
        "\n",
        "preds_buf = []\n",
        "err_buf = []\n",
        "X = train\n",
        "y=target\n",
        "\n",
        "categ_features = ['BCT_CODBUR','CTR_MATFIS','FJU_CODFJU','CTR_CESSAT','ACT_CODACT','CTR_OBLDIR','CTR_OBLACP','CTR_OBLRES',\n",
        "                  \n",
        "                  'CTR_OBLFOP','CTR_OBLTFP','CTR_OBLDCO','CTR_OBLTVA','CTR_OFODEP','CTR_OFODET','CTR_OBLAUT','CTR_OBLASS',\n",
        "                  \n",
        "                  'CTR_ODTIMB','CTR_OBLTCL','CTR_OBLTHO','CTR_OBLDLI','CTR_OBLTVI',]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOZjIpxUk3kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(n_iters): \n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=i)\n",
        "    d_train = lgb.Dataset(x_train, label=y_train,categorical_feature=categ_features)\n",
        "    d_valid = lgb.Dataset(x_valid, label=y_valid,categorical_feature=categ_features)\n",
        "\n",
        "    model = lgb.train(params, d_train,valid_sets=(d_train,d_valid) ,early_stopping_rounds=100 ,verbose_eval=100)\n",
        "\n",
        "    preds = np.clip(model.predict(x_valid,num_iteration=model.best_iteration) ,a_min=0 , a_max=100)\n",
        "    \n",
        "    err = sqrt(mean_squared_error(y_valid, preds))\n",
        "    err_buf.append(err)\n",
        "    print('RMSLE = ' + str(err))\n",
        "    \n",
        "    ######################################################   \" TEST \"  ######################################################\"\n",
        "    preds = np.clip(model.predict(test,num_iteration=model.best_iteration ), a_min=0 , a_max=100) \n",
        "    preds_buf.append(preds)\n",
        "\n",
        "print('Mean RMSLE = ' + str(np.mean(err_buf)) + ' +/- ' + str(np.std(err_buf)))\n",
        "# Average predictions\n",
        "preds = np.mean(preds_buf, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa4gn57AE2Dk",
        "colab_type": "text"
      },
      "source": [
        "# **Create a submission**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjLu6Owik3m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Submission_Cross_val_LGB = pd.DataFrame()\n",
        "Submission_Cross_val_LGB['client_id'] = testID\n",
        "Submission_Cross_val_LGB['target'] = np.clip(preds ,a_min =0, a_max=100)\n",
        "\n",
        "\n",
        "print('min' , Submission_Cross_val_LGB['target'].min() )\n",
        "print('max' , Submission_Cross_val_LGB['target'].max() )\n",
        "print('mean : ' ,Submission_Cross_val_LGB['target'].mean())\n",
        "\n",
        "Submission_Cross_val_LGB.to_csv('Submission_Cross_val_LGB_over_17800.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHBJlHSvGT55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}